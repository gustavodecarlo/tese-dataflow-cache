apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: "taxi-s-cleaned-agg-{{ macros.uuid.uuid4() }}-{{ task_instance.try_number }}"
  namespace: default
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "tese-spark:latest"
  imagePullPolicy: IfNotPresent
  mainApplicationFile: "local:///opt/spark/work-dir/cenarios/cenario_od_covid/covid_pipelines/main.py"
  arguments: [
    "cleaned-and-filter-containment",
    "--source-data",
    "gs://lncc-tese-datafrag/cmt_nycytaxi/nyc_yellow_taxi_raw",
    "--table",
    "nyc_yellow_taxi_treat",
    "--filter",
    "trip_distance >= 1.6 AND passenger_count >= 2",
    "--temp-table",
    "nyc_yellow_taxi",
    "--sql",
    "SELECT VendorID, payment_type, SUM(total_amount) total_amount, SUM(passenger_count) passenger_total, sum(trip_distance) total_trip_distance, AVG(total_amount) avg_ticket FROM nyc_yellow_taxi WHERE VendorID = 1 GROUP BY VendorID,payment_type",
    "--have-datafrag"
  ]
  hadoopConf:
    "fs.gs.impl": "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"
    "fs.AbstractFileSystem.gs.impl": "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS"
  sparkConf:
    "spark.sql.shuffle.partitions": "10"
    "spark.sql.parquet.compression.codec": "gzip"
  sparkVersion: "3.3.2"
  restartPolicy:
    type: Never
  volumes:
    - name: "test-volume"
      hostPath:
        path: "/tmp"
        type: Directory
  driver:
    cores: 3
    memory: "4000m"
    labels:
      version: 3.3.2
    serviceAccount: spark
    env:
    - name: WAREHOUSE
      value: "{{ env_config.warehouse }}"
    - name: CASSANDRA_HOST
      value: "{{ env_config.cassandra_host }}"
    - name: CASSANDRA_PORT
      value: "{{ env_config.cassandra_port }}"
    - name: GOOGLE_BUCKET
      value: "{{ env_config.google_bucket }}"
    - name: DATAFRAG_WAREHOUSE
      value: "{{ env_config.datafrag_warehouse }}"
    - name: DATAFRAG_METATABLE
      value: "{{ env_config.datafrag_metatable }}"
    - name: DATAFRAG_TC_METATABLE
      value: "{{ env_config.datafrag_tc_metatable }}"
    - name: DATAFRAG_KEYSPACE
      value: "{{ env_config.datafrag_keyspace }}"
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: "{{ env_config.google_application_credentials }}"
    volumeMounts:
      - name: "test-volume"
        mountPath: "/tmp"
  executor:
    cores: 1
    instances: 2
    memory: "2048m"
    labels:
      version: 3.3.2
    env:
    - name: WAREHOUSE
      value: "{{ env_config.warehouse }}"
    - name: CASSANDRA_HOST
      value: "{{ env_config.cassandra_host }}"
    - name: CASSANDRA_PORT
      value: "{{ env_config.cassandra_port }}"
    - name: GOOGLE_BUCKET
      value: "{{ env_config.google_bucket }}"
    - name: DATAFRAG_WAREHOUSE
      value: "{{ env_config.datafrag_warehouse }}"
    - name: DATAFRAG_METATABLE
      value: "{{ env_config.datafrag_metatable }}"
    - name: DATAFRAG_TC_METATABLE
      value: "{{ env_config.datafrag_tc_metatable }}"
    - name: DATAFRAG_KEYSPACE
      value: "{{ env_config.datafrag_keyspace }}"
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: "{{ env_config.google_application_credentials }}"
    volumeMounts:
      - name: "test-volume"
        mountPath: "/tmp"